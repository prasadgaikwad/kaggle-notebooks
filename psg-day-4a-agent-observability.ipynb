{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T19:15:08.149281Z","iopub.execute_input":"2025-11-12T19:15:08.149605Z","iopub.status.idle":"2025-11-12T19:15:08.155172Z","shell.execute_reply.started":"2025-11-12T19:15:08.149581Z","shell.execute_reply":"2025-11-12T19:15:08.154081Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üîé Agent Observability - Logs, Traces & Metrics\n\n**Welcome to Day 4 of the Kaggle 5-day Agents course!**\n\nIn Day 3, you learned the **\"What, Why & How\" of Session and Memory management**, focusing on long-term, short-term, and shared memory (state). \n\nToday, you'll learn:\n- How to add observability to the agent you've built and\n- How to evaluate if the agents are working as expected\n\nIn this notebook, we'll focus on the first part - **Agent Observability!**\n\n## What is Agent Observability?\n\n**üö® The challenge:** Unlike traditional software that fails predictably, AI agents can fail mysteriously. Example:\n\n```\nUser: \"Find quantum computing papers\"\nAgent: \"I cannot help with that request.\"\nYou: üò≠ WHY?? Is it the prompt? Missing tools? API error?\n```\n\n**üí° The Solution:** Agent observability gives you complete visibility into your agent's decision-making process. You'll see exactly what prompts are sent to the LLM, which tools are available, how the model responds, and where failures occur.\n\n```\nDEBUG Log: LLM Request shows \"Functions: []\" (no tools!)\nYou: üéØ Aha! Missing google_search tool - easy fix!\n```\n\n## Foundational pillars of Agent Observability\n\n1. **Logs:** A log is a record of a single event, telling you **what** happened at a specific moment.\n2. **Traces:** A trace connects the logs into a single story, showing you **why** a final result occurred by revealing the entire sequence of steps.\n3. **Metrics:** Metrics are the summary numbers (like averages and error rates) that tell you **how** well the agent is performing overall.\n\n<center>\n    <img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/observability-intro.png\">\n</center>\n\n**In this notebook, you'll:**\n\n* ‚úÖ Set up logging configuration\n* ‚úÖ Create a broken agent. Use `adk web` UI & logs to identify exactly why the agent fails\n* ‚úÖ Understand how to implement logging in production\n* ‚úÖ Learn when to use built-in logging vs custom solutions","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### üîë 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/), which requires an API key.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to access the `GOOGLE_API_KEY` you just saved and set it as an environment variable for the notebook to use:","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Setup and authentication complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:19:14.744912Z","iopub.execute_input":"2025-11-18T03:19:14.745188Z","iopub.status.idle":"2025-11-18T03:19:15.022758Z","shell.execute_reply.started":"2025-11-18T03:19:14.745164Z","shell.execute_reply":"2025-11-18T03:19:15.021662Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Setup and authentication complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### ‚úçÔ∏è 1.3: Set up logging and cleanup old files\nLet's configure logging for our debugging session. The following cell makes sure we also capture other log levels, like DEBUG.","metadata":{}},{"cell_type":"code","source":"import logging\nimport os\n\n# Clean up any previous logs\nfor log_file in [\"logger.log\", \"web.log\", \"tunnel.log\"]:\n    if os.path.exists(log_file):\n        os.remove(log_file)\n        print(f\"üßπ Cleaned up {log_file}\")\n\n# Configure logging with DEBUG log level.\nlogging.basicConfig(\n    filename=\"logger.log\",\n    level=logging.DEBUG,\n    format=\"%(filename)s:%(lineno)s %(levelname)s:%(message)s\",\n)\n\nprint(\"‚úÖ Logging configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:19:15.024860Z","iopub.execute_input":"2025-11-18T03:19:15.025194Z","iopub.status.idle":"2025-11-18T03:19:15.032679Z","shell.execute_reply.started":"2025-11-18T03:19:15.025171Z","shell.execute_reply":"2025-11-18T03:19:15.031716Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Logging configured\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### üíª 1.4: Set up proxy and tunneling\n\nWe'll use a proxy to access the ADK web UI from within the Kaggle Notebooks environment. If you are running this outside the Kaggle environment, you don't need to do this.","metadata":{}},{"cell_type":"code","source":"from IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n\n# Gets the proxied URL in the Kaggle Notebooks environment\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:20:19.446128Z","iopub.execute_input":"2025-11-18T03:20:19.446496Z","iopub.status.idle":"2025-11-18T03:20:21.313986Z","shell.execute_reply.started":"2025-11-18T03:20:19.446468Z","shell.execute_reply":"2025-11-18T03:20:21.312889Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"---\n## üêû Section 2: Hands-On Debugging with ADK Web UI","metadata":{}},{"cell_type":"markdown","source":"### 2.1: Create a \"Research Paper Finder\" Agent\n\n\n**Our goal:** Build a research paper finder agent that helps users find academic papers on any topic.\n\nBut first, let's intentionally create an incorrect version of the agent to practice debugging! We'll start by creating a new agent folder using the `adk create` CLI command.","metadata":{}},{"cell_type":"code","source":"!adk create research-agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:21:15.447816Z","iopub.execute_input":"2025-11-18T03:21:15.448381Z","iopub.status.idle":"2025-11-18T03:22:18.958633Z","shell.execute_reply.started":"2025-11-18T03:21:15.448354Z","shell.execute_reply":"2025-11-18T03:22:18.957150Z"}},"outputs":[{"name":"stdout","text":"\u001b[32m\nAgent created in /kaggle/working/research-agent:\n- .env\n- __init__.py\n- agent.py\n\u001b[0m\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Agent definition\n\nNext, let's create our root agent. \n- We'll configure it as an `LlmAgent`, give it a name, model and instruction.\n- The `root_agent` gets the user prompt and delegates the search to the `google_search_agent`.\n- Then, the agent uses the `count_papers` tool to count the number of papers returned.\n\n**üëâ Pay attention to the root agent's instructions and the `count_papers` tool parameter!**","metadata":{}},{"cell_type":"code","source":"%%writefile research-agent/agent.py\n\nfrom google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.google_search_tool import google_search\n\nfrom google.genai import types\nfrom typing import List\n\nretry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)\n\n# ---- Intentionally pass incorrect datatype - `str` instead of `List[str]` ----\ndef count_papers(papers: List[str]):\n    \"\"\"\n    This function counts the number of papers in a list of strings.\n    Args:\n      papers: A list of strings, where each string is a research paper.\n    Returns:\n      The number of papers in the list.\n    \"\"\"\n    return len(papers)\n\n\n# Google Search agent\ngoogle_search_agent = LlmAgent(\n    name=\"google_search_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Searches for information using Google search\",\n    instruction=\"\"\"Use the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\"\"\",\n    tools=[google_search]\n)\n\n\n# Root agent\nroot_agent = LlmAgent(\n    name=\"research_paper_finder_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"Your task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the 'google_search_agent'. \n    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \"\"\",\n    tools=[AgentTool(agent=google_search_agent), count_papers]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:33:49.276304Z","iopub.execute_input":"2025-11-18T03:33:49.277231Z","iopub.status.idle":"2025-11-18T03:33:49.286261Z","shell.execute_reply.started":"2025-11-18T03:33:49.277182Z","shell.execute_reply":"2025-11-18T03:33:49.285053Z"}},"outputs":[{"name":"stdout","text":"Overwriting research-agent/agent.py\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### 2.2: Run the agent\n\nLet's now run our agent with the `adk web --log_level DEBUG` CLI command.\n\n**üìç The key here is `--log_level DEBUG`** - this shows us:\n\n\n* **Full LLM Prompts:** The complete request sent to the language model, including system instructions, history, and tools.\n* Detailed API responses from services.\n* Internal state transitions and variable values.\n\nOther log levels include: INFO, ERROR and WARNING.","metadata":{}},{"cell_type":"markdown","source":"Get the proxied URL to access the ADK web UI in the Kaggle Notebooks environment:","metadata":{}},{"cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:33:54.661301Z","iopub.execute_input":"2025-11-18T03:33:54.661699Z","iopub.status.idle":"2025-11-18T03:33:54.671139Z","shell.execute_reply.started":"2025-11-18T03:33:54.661674Z","shell.execute_reply":"2025-11-18T03:33:54.670018Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>‚ö†Ô∏è IMPORTANT: Action Required</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            The ADK web UI is <strong>not running yet</strong>. You must start it in the next cell.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Run the next cell</strong> (the one with <code>!adk web ...</code>) to start the ADK web UI.</li>\n                <li style=\"margin-bottom: 5px;\">Wait for that cell to show it is \"Running\" (it will not \"complete\").</li>\n                <li>Once it's running, <strong>return to this button</strong> and click it to open the UI.</li>\n            </ol>\n            <em style=\"font-size: 0.9em; color: #555;\">(If you click the button before running the next cell, you will get a 500 error.)</em>\n        </div>\n        <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/279359953/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..h2qU-LNcqS2dWztpAGbkxw.U3gHEIGb9wamP8Bm3k616lg1kFpTNNg0dFvUcSBOZH_-FpAReJjoECEtj9Hk8ahTOcrZ0AGZN0v5mpOrGpOFXqDHao-OzQy3ovbylHxIWXBq1ljB0DOxEOsF9dFnTjzAu5Dm_nl9j_NH-6xr4tlpvkpdAzJeh-SHj6sjAr-Qq7AnrUukni6RBvDGx7enebO6H5i5l9-_LCSqac4dFB4iaYJINKz3sBNEYeicS-NUyrWkRQ1ATcsIzNfUyrf7Q8W8.RDsY9IuY5fn_f3gn19XGDA/proxy/proxy/8000' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after running cell below) ‚Üó\n        </a>\n    </div>\n    "},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Now you can start the ADK web UI with the `--log_level` parameter.\n\nüëâ **Note:** The following cell will not \"complete\", but will remain running and serving the ADK web UI until you manually stop the cell.","metadata":{}},{"cell_type":"code","source":"!adk web --log_level DEBUG --url_prefix {url_prefix}","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:33:58.182839Z","iopub.execute_input":"2025-11-18T03:33:58.183175Z","iopub.status.idle":"2025-11-18T03:35:46.323073Z","shell.execute_reply.started":"2025-11-18T03:33:58.183149Z","shell.execute_reply":"2025-11-18T03:35:46.321587Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m84\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n\u001b[32mINFO\u001b[0m:     35.191.82.123:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.120:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.120:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.120:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nINFO:google_adk.google.adk.cli.adk_web_server:New session created: 6504be05-d05f-4fc2-a791-6aa25c2b9422\n\u001b[32mINFO\u001b[0m:     35.191.82.121:0 - \"\u001b[1mPOST /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mGET /builder/app/research-agent?ts=1763436873615 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.123:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/6504be05-d05f-4fc2-a791-6aa25c2b9422 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mGET /apps/research-agent/eval_sets HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.122:0 - \"\u001b[1mGET /apps/research-agent/eval_results HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mGET /debug/trace/session/6504be05-d05f-4fc2-a791-6aa25c2b9422 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.123:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'appName' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'userId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'sessionId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'newMessage' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'streaming' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'stateDelta' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validation_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'validation_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'serialization_alias' attribute with value 'invocationId' was provided to the `Field()` function, which has no effect in the context it was used. 'serialization_alias' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mPOST /run_sse HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nDEBUG:google_adk.google.adk.cli.utils.agent_loader:Loading agent research-agent - not in cache.\nDEBUG:google_adk.google.adk.cli.utils.agent_loader:Loading .env for agent research-agent from /kaggle/working\nDEBUG:google_adk.google.adk.cli.utils.agent_loader:Module research-agent has no root_agent. Trying next pattern.\nINFO:google_adk.google.adk.cli.utils.agent_loader:Found root_agent in research-agent.agent\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Request:\n-----------------------------------------------------------\nSystem Instruction:\nYour task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the 'google_search_agent'. \n    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is \"research_paper_finder_agent\".\n-----------------------------------------------------------\nConfig:\n{'tools': [{}]}\n-----------------------------------------------------------\nContents:\n{\"parts\":[{\"text\":\"give me research papers on deep learning\\n\"}],\"role\":\"user\"}\n-----------------------------------------------------------\nFunctions:\ngoogle_search_agent: {'request': {'type': <Type.STRING: 'STRING'>}} \ncount_papers: {'papers': {'items': {'type': <Type.STRING: 'STRING'>}, 'type': <Type.ARRAY: 'ARRAY'>}} \n-----------------------------------------------------------\n\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Response:\n-----------------------------------------------------------\nText:\nNone\n-----------------------------------------------------------\nFunction calls:\nname: google_search_agent, args: {'request': 'research papers on deep learning'}\n-----------------------------------------------------------\nRaw response:\n{\"sdk_http_response\":{\"headers\":{\"Content-Type\":\"application/json; charset=UTF-8\",\"Vary\":\"Origin, X-Origin, Referer\",\"Content-Encoding\":\"gzip\",\"Date\":\"Tue, 18 Nov 2025 03:34:57 GMT\",\"Server\":\"scaffolding on HTTPServer2\",\"X-XSS-Protection\":\"0\",\"X-Frame-Options\":\"SAMEORIGIN\",\"X-Content-Type-Options\":\"nosniff\",\"Server-Timing\":\"gfet4t7; dur=446\",\"Transfer-Encoding\":\"chunked\"}},\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{\"request\":\"research papers on deep learning\"},\"name\":\"google_search_agent\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"index\":0}],\"model_version\":\"gemini-2.5-flash-lite\",\"response_id\":\"YekbaebxKcSmvr0PgPzBQA\",\"usage_metadata\":{\"candidates_token_count\":21,\"prompt_token_count\":243,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":243}],\"total_token_count\":264}}\n-----------------------------------------------------------\n\nDEBUG:google_adk.google.adk.cli.adk_web_server:Generated event in agent run streaming: {\"modelVersion\":\"gemini-2.5-flash-lite\",\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"adk-5bc7aad2-66a8-4ad6-a14f-5f780934296a\",\"args\":{\"request\":\"research papers on deep learning\"},\"name\":\"google_search_agent\"}}],\"role\":\"model\"},\"finishReason\":\"STOP\",\"usageMetadata\":{\"candidatesTokenCount\":21,\"promptTokenCount\":243,\"promptTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":243}],\"totalTokenCount\":264},\"invocationId\":\"e-c38ddd75-ce77-4076-9def-0f33efe9a518\",\"author\":\"research_paper_finder_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{},\"requestedToolConfirmations\":{}},\"longRunningToolIds\":[],\"id\":\"bc86dd1e-0dd3-4bcb-9a89-3f72fd750416\",\"timestamp\":1763436897.082232}\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Request:\n-----------------------------------------------------------\nSystem Instruction:\nUse the google_search tool to find information on the given topic. Return the raw search results.\n    If the user asks for a list of papers, then give them the list of research papers you found and not the summary.\n\nYou are an agent. Your internal name is \"google_search_agent\". The description about you is \"Searches for information using Google search\".\n-----------------------------------------------------------\nConfig:\n{}\n-----------------------------------------------------------\nContents:\n{\"parts\":[{\"text\":\"research papers on deep learning\"}],\"role\":\"user\"}\n-----------------------------------------------------------\nFunctions:\n\n-----------------------------------------------------------\n\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Response:\n-----------------------------------------------------------\nText:\nDeep learning research has a rich history, with many foundational and impactful papers shaping the field. Here are some key research papers and areas to explore:\n\n**Seminal and Foundational Papers:**\n\n*   **\"Computing Machinery and Intelligence\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\n*   **\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\n*   **\"LSTM: Long Short-Term Memory\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\n*   **\"LeNet: Gradient-Based Learning Applied to Document Recognition\" (1998):** This work by LeCun et al. introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\n*   **\"ImageNet Classification with Deep Convolutional Neural Networks\" (2012):** Often referred to as the \"AlexNet\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\n*   **\"Playing Atari with Deep Reinforcement Learning\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\n*   **\"Generative Adversarial Nets\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\n*   **\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\n*   **\"Very Deep Convolutional Networks for Large-Scale Image Recognition\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\n*   **\"Deep Residual Learning for Image Recognition\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\n*   **\"Attention Is All You Need\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\n\n**Key Research Areas and Recent Developments:**\n\n*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\n*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\n*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\n*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\n*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\n*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\n*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\n*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\n*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\n\nThis list is not exhaustive, as the field of deep learning is rapidly evolving with new research published continuously. Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\n-----------------------------------------------------------\nFunction calls:\n\n-----------------------------------------------------------\nRaw response:\n{\"sdk_http_response\":{\"headers\":{\"Content-Type\":\"application/json; charset=UTF-8\",\"Vary\":\"Origin, X-Origin, Referer\",\"Content-Encoding\":\"gzip\",\"Date\":\"Tue, 18 Nov 2025 03:35:03 GMT\",\"Server\":\"scaffolding on HTTPServer2\",\"X-XSS-Protection\":\"0\",\"X-Frame-Options\":\"SAMEORIGIN\",\"X-Content-Type-Options\":\"nosniff\",\"Server-Timing\":\"gfet4t7; dur=5524\",\"Transfer-Encoding\":\"chunked\"}},\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"Deep learning research has a rich history, with many foundational and impactful papers shaping the field. Here are some key research papers and areas to explore:\\n\\n**Seminal and Foundational Papers:**\\n\\n*   **\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\\n*   **\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\\n*   **\\\"LSTM: Long Short-Term Memory\\\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\\n*   **\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998):** This work by LeCun et al. introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\\n*   **\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012):** Often referred to as the \\\"AlexNet\\\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\\n*   **\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\\n*   **\\\"Generative Adversarial Nets\\\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\\n*   **\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\\n*   **\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\\n*   **\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\\n*   **\\\"Attention Is All You Need\\\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\\n\\n**Key Research Areas and Recent Developments:**\\n\\n*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\\n*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\\n*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\\n*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\\n*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\\n*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\\n*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\\n*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\\n*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\\n\\nThis list is not exhaustive, as the field of deep learning is rapidly evolving with new research published continuously. Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"grounding_metadata\":{\"grounding_chunks\":[{\"web\":{\"title\":\"substack.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxzT019BvIlOMDOw8UNVrewz-CGpHpCfVuCNLyWkHkyi75wPYc4DUGhc7GB3shC0QwOSGk5Adn24iZdU_ZTbRbrxwLgAUl7YXFVtAho_SFuNmWUgVgNzWnRngCoQaNDvwygh4Fr5Bx-AOkXDXwZvXoKIiY3jL8RHuULcrldyB_\"}},{\"web\":{\"title\":\"baulab.info\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHG3UdpTwKyTkyohvBM1AjvzdKeT-h_bd8GL60P1LMDhPx_9K14zs2c_VBj0Y341i4m1Qu3LwwSom57egPfRda7CU_kqDTRkPOT0DWS0pTo6eXnxEiQ\"}},{\"web\":{\"title\":\"mdpi.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHs_dSiMWUpd3nHJdHDMAwMJ7UMQ8MrigGUu-ImUe3nSbIBEGWEWaA19QUgzvB-8VgDO7-vcMw360k8pqr4OYuJ5SODZRFIXGWI7RYL3K1OQFwsSd6FZiNKMLR3hopAxqXPKw==\"}},{\"web\":{\"title\":\"researchgate.net\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGYbzJZeFdlr6pMkaK8lJntlWbX4dsIOtBfGjLlzNsPFo1viN0BKjHsMpR-wEUs4Ke_d0B-W6H3jAxxVDANAUhisym1iq077SiR9CWSJQ5srbM6E5qC0VdQ6UVX2BVKE-x5rjj1XzoWLY6CHjp1hPdW7bpVHgdg5qrXiDVljw1eSfXAgTDZJts54FTY2jTFRLhwgcw0-xTFh3a8Jg9ruQMaw228BukmNrNn-w==\"}},{\"web\":{\"title\":\"github.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFBGJRGrAizEvTLpJyUBW5QAvnvMNG4C_wqc2DvDVj6X1xJKZEidMdoH8cA59WVkXqqx4T4AB6DANZbUuTLsKvjSFfEncr_CotftKLUKURIzsiJTEvM97G0_mcSBehwVn82Z1FJTA==\"}},{\"web\":{\"title\":\"medium.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGx7oMVPXuF6Im695Ksg96fVAvtsk_dJUnapc-Gqy8p660nBc_IOMwWIPJsrGamOqEocS7Ovqf6ZvH77hoOaofbIe06sACy_02rpjNEiNgHjQyqN5tqHORSKZDgY-FgeIn2x22tnCQGld6QlD1Wn9w4DXFwgeyUUxf-ZBZwXYyyiadbwt2W1lmxI6LRq8NfwTcGu4DiJbnx8zh05W8eYFlQ0u2d7M7ke80=\"}},{\"web\":{\"title\":\"geeksforgeeks.org\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGzcZ3QidSv6VZQRqKBir37LbBGBhvtsQr8AyfQsJ1sDoyusJVJDC789xBqY-Xh3moWPhCxyRMdG68AcqhmP6T4bckhUhWziU2kzD3gfgYb65Uor9IGGBAZZ7lyidVrE3miHlkvR20AK3L4EwQjZhnkt7HQmge0d5e88rzrPIhiK04ROHJvQ_dSzHuFzZDPbwhpoQtTEidt\"}},{\"web\":{\"title\":\"github.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFPoDJLt77iEZYoV49Dno_nEKVY7Pv1tidie-TjEIe-TMdwAP_CaMjMKhI2JemR628b83u-KkC8n6hbIx4lpTQpw0pKJ2DIZnrUmiX2O7_GmfNNIZEtA0z8QDdG83XN2SLv8yi9qZ1gO17tQegRRjTShQ==\"}},{\"web\":{\"title\":\"kdnuggets.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHUlY9wibQ44Wxu8WGkrkUTEL_GcROxbWXe_xL16dErBjqPkUc40BmgXDaCrCbCi__TMEN_n0_eaUzHW9nhS4vj_gVbTJ0NtTgI1jtkEppIG2kGCepSvZsTSODrKzFv6f-vfE2cR59lATWKdVaQ6IBWNyolLrABxeLxZs4wAMlW\"}},{\"web\":{\"title\":\"ibm.com\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFf8SXQrgfLG-ZP40_qpBP4SepAP5o-0_A3IaMjny7_uCRAfxKEWr7vy3gzpOaN8nmTe0n9hWJzVEboMwRAtgAI900RJU-qQd6kFCnmSGwQezte0X3KsWBjhqQ0omPto1fFu-Dx-OQ2hg==\"}},{\"web\":{\"title\":\"arxiv.org\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHmYVqtj3957N7PjNLgmCSrLkek0ngBBoAD8Am4Zq_R9abmbkN_KioUCGw2qUaoeHkti3vdGYtos2ckQru97Vbm1ZHEselYBG8PKxoU0pAthbx4C58czJquJ28=\"}},{\"web\":{\"title\":\"research.google\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFE7f-C7Zh4i0ay6g4nB_DLyUTmz72BkX_kgNjLm22QXasfZ33DibOfhJq96iPhS4kNwIIRBFrQNGog5pO6SoS8pikbf9X-w6Hid48x4GfuAK0RQDYMBvaHxKFMf6t4K606UjM5h6oBMCWkfqv1A3xzoZQq-krp-_HAmJS0XzlQKQqFSG1m55y2rwg79PLSpKhwKNDxagnzOVYfwsY=\"}},{\"web\":{\"title\":\"paperguide.ai\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFiiGqtBEggSX-QI5fomNjp27j9RX9LD5WIWLtrwGxaiFuVBimu7_6SqugqCN-lmai4g_J7Huy_fvqoMW2LMrJEVP_e_cIZ4jKqm0CIEn-YWTAKYI9wm7JqWcp_Ii3xTHhB8mnwx93dEr5jpZ6ukL6YgDzrftb7TO5f\"}},{\"web\":{\"title\":\"icml.cc\",\"uri\":\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE0oD_xiydYLmVdaTPRnDg80Gz0wgvbUnXQvOUw0tGJLDq3YZcz_sZrpusQCzFkYMSMBOsDLAB5DSa2yKrgCYFwDNDlTCcB-DGSlyYxJ2FYrU3C_gg6j9zQXgzRohAFq7pc3g==\"}}],\"grounding_supports\":[{\"grounding_chunk_indices\":[0],\"segment\":{\"end_index\":413,\"start_index\":201,\"text\":\"*   **\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\"}},{\"grounding_chunk_indices\":[0,1],\"segment\":{\"end_index\":665,\"start_index\":414,\"text\":\"*   **\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\"}},{\"grounding_chunk_indices\":[0,1,2],\"segment\":{\"end_index\":911,\"start_index\":666,\"text\":\"*   **\\\"LSTM: Long Short-Term Memory\\\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\"}},{\"grounding_chunk_indices\":[0,3,4],\"segment\":{\"end_index\":1128,\"start_index\":1019,\"text\":\"introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\"}},{\"grounding_chunk_indices\":[0,5,2,6,4],\"segment\":{\"end_index\":1423,\"start_index\":1129,\"text\":\"*   **\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012):** Often referred to as the \\\"AlexNet\\\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\"}},{\"grounding_chunk_indices\":[0,6],\"segment\":{\"end_index\":1645,\"start_index\":1424,\"text\":\"*   **\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\"}},{\"grounding_chunk_indices\":[0,1,5,7,6],\"segment\":{\"end_index\":1827,\"start_index\":1646,\"text\":\"*   **\\\"Generative Adversarial Nets\\\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\"}},{\"grounding_chunk_indices\":[0,1,8,7],\"segment\":{\"end_index\":2044,\"start_index\":1828,\"text\":\"*   **\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\"}},{\"grounding_chunk_indices\":[0],\"segment\":{\"end_index\":2311,\"start_index\":2045,\"text\":\"*   **\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\"}},{\"grounding_chunk_indices\":[5,8,6,4],\"segment\":{\"end_index\":2549,\"start_index\":2312,\"text\":\"*   **\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\"}},{\"grounding_chunk_indices\":[5,6,9],\"segment\":{\"end_index\":2775,\"start_index\":2550,\"text\":\"*   **\\\"Attention Is All You Need\\\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\"}},{\"grounding_chunk_indices\":[1,2,3,4],\"segment\":{\"end_index\":3004,\"start_index\":2826,\"text\":\"*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\"}},{\"grounding_chunk_indices\":[1,2,9],\"segment\":{\"end_index\":3128,\"start_index\":3005,\"text\":\"*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\"}},{\"grounding_chunk_indices\":[1,2,7,6],\"segment\":{\"end_index\":3316,\"start_index\":3129,\"text\":\"*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\"}},{\"grounding_chunk_indices\":[2,10,9],\"segment\":{\"end_index\":3499,\"start_index\":3317,\"text\":\"*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\"}},{\"grounding_chunk_indices\":[0,2,6],\"segment\":{\"end_index\":3644,\"start_index\":3500,\"text\":\"*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\"}},{\"grounding_chunk_indices\":[2],\"segment\":{\"end_index\":3820,\"start_index\":3645,\"text\":\"*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\"}},{\"grounding_chunk_indices\":[2],\"segment\":{\"end_index\":3971,\"start_index\":3821,\"text\":\"*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\"}},{\"grounding_chunk_indices\":[11],\"segment\":{\"end_index\":4089,\"start_index\":3972,\"text\":\"*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\"}},{\"grounding_chunk_indices\":[12,2,10],\"segment\":{\"end_index\":4248,\"start_index\":4090,\"text\":\"*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\"}},{\"grounding_chunk_indices\":[13],\"segment\":{\"end_index\":4516,\"start_index\":4371,\"text\":\"Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\"}}],\"search_entry_point\":{\"rendered_content\":\"<style>\\n.container {\\n  align-items: center;\\n  border-radius: 8px;\\n  display: flex;\\n  font-family: Google Sans, Roboto, sans-serif;\\n  font-size: 14px;\\n  line-height: 20px;\\n  padding: 8px 12px;\\n}\\n.chip {\\n  display: inline-block;\\n  border: solid 1px;\\n  border-radius: 16px;\\n  min-width: 14px;\\n  padding: 5px 16px;\\n  text-align: center;\\n  user-select: none;\\n  margin: 0 8px;\\n  -webkit-tap-highlight-color: transparent;\\n}\\n.carousel {\\n  overflow: auto;\\n  scrollbar-width: none;\\n  white-space: nowrap;\\n  margin-right: -12px;\\n}\\n.headline {\\n  display: flex;\\n  margin-right: 4px;\\n}\\n.gradient-container {\\n  position: relative;\\n}\\n.gradient {\\n  position: absolute;\\n  transform: translate(3px, -9px);\\n  height: 36px;\\n  width: 9px;\\n}\\n@media (prefers-color-scheme: light) {\\n  .container {\\n    background-color: #fafafa;\\n    box-shadow: 0 0 0 1px #0000000f;\\n  }\\n  .headline-label {\\n    color: #1f1f1f;\\n  }\\n  .chip {\\n    background-color: #ffffff;\\n    border-color: #d2d2d2;\\n    color: #5e5e5e;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:focus {\\n    background-color: #f2f2f2;\\n  }\\n  .chip:active {\\n    background-color: #d8d8d8;\\n    border-color: #b6b6b6;\\n  }\\n  .logo-dark {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\\n  }\\n}\\n@media (prefers-color-scheme: dark) {\\n  .container {\\n    background-color: #1f1f1f;\\n    box-shadow: 0 0 0 1px #ffffff26;\\n  }\\n  .headline-label {\\n    color: #fff;\\n  }\\n  .chip {\\n    background-color: #2c2c2c;\\n    border-color: #3c4043;\\n    color: #fff;\\n    text-decoration: none;\\n  }\\n  .chip:hover {\\n    background-color: #353536;\\n  }\\n  .chip:focus {\\n    background-color: #353536;\\n  }\\n  .chip:active {\\n    background-color: #464849;\\n    border-color: #53575b;\\n  }\\n  .logo-light {\\n    display: none;\\n  }\\n  .gradient {\\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\\n  }\\n}\\n</style>\\n<div class=\\\"container\\\">\\n  <div class=\\\"headline\\\">\\n    <svg class=\\\"logo-light\\\" width=\\\"18\\\" height=\\\"18\\\" viewBox=\\\"9 9 35 35\\\" fill=\\\"none\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n      <path fill-rule=\\\"evenodd\\\" clip-rule=\\\"evenodd\\\" d=\\\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\\\" fill=\\\"#4285F4\\\"/>\\n      <path fill-rule=\\\"evenodd\\\" clip-rule=\\\"evenodd\\\" d=\\\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\\\" fill=\\\"#34A853\\\"/>\\n      <path fill-rule=\\\"evenodd\\\" clip-rule=\\\"evenodd\\\" d=\\\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\\\" fill=\\\"#FBBC05\\\"/>\\n      <path fill-rule=\\\"evenodd\\\" clip-rule=\\\"evenodd\\\" d=\\\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\\\" fill=\\\"#EA4335\\\"/>\\n    </svg>\\n    <svg class=\\\"logo-dark\\\" width=\\\"18\\\" height=\\\"18\\\" viewBox=\\\"0 0 48 48\\\" xmlns=\\\"http://www.w3.org/2000/svg\\\">\\n      <circle cx=\\\"24\\\" cy=\\\"23\\\" fill=\\\"#FFF\\\" r=\\\"22\\\"/>\\n      <path d=\\\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\\\" fill=\\\"#4285F4\\\"/>\\n      <path d=\\\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\\\" fill=\\\"#34A853\\\"/>\\n      <path d=\\\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\\\" fill=\\\"#FBBC05\\\"/>\\n      <path d=\\\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\\\" fill=\\\"#EA4335\\\"/>\\n    </svg>\\n    <div class=\\\"gradient-container\\\"><div class=\\\"gradient\\\"></div></div>\\n  </div>\\n  <div class=\\\"carousel\\\">\\n    <a class=\\\"chip\\\" href=\\\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHPl4SJEkZa2TjONzjZ7KOyLUrUcVLIqZLQFGfRLF6LjipYTWHhlLSzzC5eiSCjdN6epd50Agc9MZtQadE-vMgdE3Nm0b9KCPdyPdANPAPrjgLRTKskW03s0auQXNoXQLzQfnsjdlDf6xHo2vEfDRCH8VJw_dzFRNDURp7lRFnFj1_xh9rceixOHTgmxpWYikJFpr47A9RAZHms8cAzxodg3ln5gyv1\\\">recent deep learning research papers</a>\\n    <a class=\\\"chip\\\" href=\\\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF_jCsW2yrrnj-i_85V-RIyscgf_XqBDiEnbicZ_6G67nJZHyn3r1QirGyQUVA1kGbe8XnO0STs3MInjM3zn0i7Rs8aoVnBwD7CfmORrute-eCnl3_BXPeIlspfPBk41-my4kqXaiSRY5qQBARUwOx2mKTLCocLjX9lmgfifewVzxt9A9v6HLA9SixmoWioPC4cEu4QheIAOBxCfTBuO0YswgOQ\\\">key research papers deep learning</a>\\n    <a class=\\\"chip\\\" href=\\\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHiNNVXrkG5u-es293Vl24ThIO1YKsk9oFok4UFfUu3lCfDDrxLJM8X597Eycu7Sh-K0U-tYhfjv1lPor3n7W3JukIlVd5CcmU2JS8b9b60oiHW5sEEKLJ6Ve48sqKG_HKiYnWo00jeR8qQIqsLNTrrezfcBEEDJ8YVaeRTRDEf9MemGgWD4Oqwg0l6hppgxjYuL8nZE9rDwgNbo9_cCR4lQb0=\\\">research papers on deep learning</a>\\n    <a class=\\\"chip\\\" href=\\\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHpCQQJj_4RVG8ZNnijkxCyeeWbjCNUF9j2ir-xD3ZjSijlszf-sAp7wXrj8EPEHyq3aoXYdQJIsySVHW3QLmIWclPWPd_bbu9yQYMZM-1_p5Vai8GhX6gE4eqT6ewElvNk3SkJJSPfYJn6p4uLaQT5TslekzeXvMYJJiCUV7Nf8S6LoGzTnOduIkdaGruC6xSP4xPGXRvaMI4xBuPdRw==\\\">seminal papers deep learning</a>\\n  </div>\\n</div>\\n\"},\"web_search_queries\":[\"research papers on deep learning\",\"key research papers deep learning\",\"seminal papers deep learning\",\"recent deep learning research papers\"]},\"index\":0}],\"model_version\":\"gemini-2.5-flash-lite\",\"response_id\":\"Z-kbae-XFYW21e8PhK_T4Ac\",\"usage_metadata\":{\"candidates_token_count\":1001,\"prompt_token_count\":85,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":85}],\"tool_use_prompt_token_count\":122,\"tool_use_prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":122}],\"total_token_count\":1208},\"automatic_function_calling_history\":[]}\n-----------------------------------------------------------\n\nDEBUG:google_adk.google.adk.cli.adk_web_server:Generated event in agent run streaming: {\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"adk-5bc7aad2-66a8-4ad6-a14f-5f780934296a\",\"name\":\"google_search_agent\",\"response\":{\"result\":\"Deep learning research has a rich history, with many foundational and impactful papers shaping the field. Here are some key research papers and areas to explore:\\n\\n**Seminal and Foundational Papers:**\\n\\n*   **\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\\n*   **\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\\n*   **\\\"LSTM: Long Short-Term Memory\\\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\\n*   **\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998):** This work by LeCun et al. introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\\n*   **\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012):** Often referred to as the \\\"AlexNet\\\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\\n*   **\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\\n*   **\\\"Generative Adversarial Nets\\\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\\n*   **\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\\n*   **\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\\n*   **\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\\n*   **\\\"Attention Is All You Need\\\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\\n\\n**Key Research Areas and Recent Developments:**\\n\\n*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\\n*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\\n*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\\n*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\\n*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\\n*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\\n*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\\n*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\\n*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\\n\\nThis list is not exhaustive, as the field of deep learning is rapidly evolving with new research published continuously. Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\"}}}],\"role\":\"user\"},\"invocationId\":\"e-c38ddd75-ce77-4076-9def-0f33efe9a518\",\"author\":\"research_paper_finder_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{},\"requestedToolConfirmations\":{}},\"id\":\"dcaaaef2-4038-4a08-9440-363f581dfa88\",\"timestamp\":1763436903.524261}\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Request:\n-----------------------------------------------------------\nSystem Instruction:\nYour task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the 'google_search_agent'. \n    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is \"research_paper_finder_agent\".\n-----------------------------------------------------------\nConfig:\n{'tools': [{}]}\n-----------------------------------------------------------\nContents:\n{\"parts\":[{\"text\":\"give me research papers on deep learning\\n\"}],\"role\":\"user\"}\n{\"parts\":[{\"function_call\":{\"args\":{\"request\":\"research papers on deep learning\"},\"name\":\"google_search_agent\"}}],\"role\":\"model\"}\n{\"parts\":[{\"function_response\":{\"name\":\"google_search_agent\",\"response\":{\"result\":\"Deep learning research has a rich history, with many foundational and impactful papers shaping the field. Here are some key research papers and areas to explore:\\n\\n**Seminal and Foundational Papers:**\\n\\n*   **\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\\n*   **\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\\n*   **\\\"LSTM: Long Short-Term Memory\\\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\\n*   **\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998):** This work by LeCun et al. introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\\n*   **\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012):** Often referred to as the \\\"AlexNet\\\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\\n*   **\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\\n*   **\\\"Generative Adversarial Nets\\\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\\n*   **\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\\n*   **\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\\n*   **\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\\n*   **\\\"Attention Is All You Need\\\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\\n\\n**Key Research Areas and Recent Developments:**\\n\\n*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\\n*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\\n*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\\n*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\\n*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\\n*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\\n*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\\n*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\\n*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\\n\\nThis list is not exhaustive, as the field of deep learning is rapidly evolving with new research published continuously. Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\"}}}],\"role\":\"user\"}\n-----------------------------------------------------------\nFunctions:\ngoogle_search_agent: {'request': {'type': <Type.STRING: 'STRING'>}} \ncount_papers: {'papers': {'items': {'type': <Type.STRING: 'STRING'>}, 'type': <Type.ARRAY: 'ARRAY'>}} \n-----------------------------------------------------------\n\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Response:\n-----------------------------------------------------------\nText:\nNone\n-----------------------------------------------------------\nFunction calls:\nname: count_papers, args: {'papers': ['\"Computing Machinery and Intelligence\" by Alan Turing (1950)', '\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\" by Frank Rosenblatt (1958)', '\"LSTM: Long Short-Term Memory\" (1997)', '\"LeNet: Gradient-Based Learning Applied to Document Recognition\" (1998)', '\"ImageNet Classification with Deep Convolutional Neural Networks\" (2012)', '\"Playing Atari with Deep Reinforcement Learning\" (2013)', '\"Generative Adversarial Nets\" (2014)', '\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" (2014)', '\"Very Deep Convolutional Networks for Large-Scale Image Recognition\" (VGG) (2014)', '\"Deep Residual Learning for Image Recognition\" (ResNet) (2015)', '\"Attention Is All You Need\" (2017)']}\n-----------------------------------------------------------\nRaw response:\n{\"sdk_http_response\":{\"headers\":{\"Content-Type\":\"application/json; charset=UTF-8\",\"Vary\":\"Origin, X-Origin, Referer\",\"Content-Encoding\":\"gzip\",\"Date\":\"Tue, 18 Nov 2025 03:35:04 GMT\",\"Server\":\"scaffolding on HTTPServer2\",\"X-XSS-Protection\":\"0\",\"X-Frame-Options\":\"SAMEORIGIN\",\"X-Content-Type-Options\":\"nosniff\",\"Server-Timing\":\"gfet4t7; dur=1066\",\"Transfer-Encoding\":\"chunked\"}},\"candidates\":[{\"content\":{\"parts\":[{\"function_call\":{\"args\":{\"papers\":[\"\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950)\",\"\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958)\",\"\\\"LSTM: Long Short-Term Memory\\\" (1997)\",\"\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998)\",\"\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012)\",\"\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013)\",\"\\\"Generative Adversarial Nets\\\" (2014)\",\"\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014)\",\"\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014)\",\"\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015)\",\"\\\"Attention Is All You Need\\\" (2017)\"]},\"name\":\"count_papers\"}}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"index\":0}],\"model_version\":\"gemini-2.5-flash-lite\",\"response_id\":\"aOkbaaTlGtuJ1e8PluKsMQ\",\"usage_metadata\":{\"candidates_token_count\":210,\"prompt_token_count\":1256,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":1256}],\"total_token_count\":1466}}\n-----------------------------------------------------------\n\nDEBUG:google_adk.google.adk.cli.adk_web_server:Generated event in agent run streaming: {\"modelVersion\":\"gemini-2.5-flash-lite\",\"content\":{\"parts\":[{\"functionCall\":{\"id\":\"adk-4d1467fb-49af-4609-83cd-41ee0bff9500\",\"args\":{\"papers\":[\"\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950)\",\"\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958)\",\"\\\"LSTM: Long Short-Term Memory\\\" (1997)\",\"\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998)\",\"\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012)\",\"\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013)\",\"\\\"Generative Adversarial Nets\\\" (2014)\",\"\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014)\",\"\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014)\",\"\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015)\",\"\\\"Attention Is All You Need\\\" (2017)\"]},\"name\":\"count_papers\"}}],\"role\":\"model\"},\"finishReason\":\"STOP\",\"usageMetadata\":{\"candidatesTokenCount\":210,\"promptTokenCount\":1256,\"promptTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":1256}],\"totalTokenCount\":1466},\"invocationId\":\"e-c38ddd75-ce77-4076-9def-0f33efe9a518\",\"author\":\"research_paper_finder_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{},\"requestedToolConfirmations\":{}},\"longRunningToolIds\":[],\"id\":\"ac95934b-eab0-4895-939b-e4bafb44694b\",\"timestamp\":1763436903.526104}\nDEBUG:google_adk.google.adk.cli.adk_web_server:Generated event in agent run streaming: {\"content\":{\"parts\":[{\"functionResponse\":{\"id\":\"adk-4d1467fb-49af-4609-83cd-41ee0bff9500\",\"name\":\"count_papers\",\"response\":{\"result\":11}}}],\"role\":\"user\"},\"invocationId\":\"e-c38ddd75-ce77-4076-9def-0f33efe9a518\",\"author\":\"research_paper_finder_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{},\"requestedToolConfirmations\":{}},\"id\":\"1070a8a3-e186-449a-871d-f6c49e4a7586\",\"timestamp\":1763436904.603199}\nINFO:google_adk.google.adk.models.google_llm:Sending out request, model: gemini-2.5-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Request:\n-----------------------------------------------------------\nSystem Instruction:\nYour task is to find research papers and count them. \n\n    You MUST ALWAYS follow these steps:\n    1) Find research papers on the user provided topic using the 'google_search_agent'. \n    2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n    3) Return both the list of research papers and the total number of papers.\n    \n\nYou are an agent. Your internal name is \"research_paper_finder_agent\".\n-----------------------------------------------------------\nConfig:\n{'tools': [{}]}\n-----------------------------------------------------------\nContents:\n{\"parts\":[{\"text\":\"give me research papers on deep learning\\n\"}],\"role\":\"user\"}\n{\"parts\":[{\"function_call\":{\"args\":{\"request\":\"research papers on deep learning\"},\"name\":\"google_search_agent\"}}],\"role\":\"model\"}\n{\"parts\":[{\"function_response\":{\"name\":\"google_search_agent\",\"response\":{\"result\":\"Deep learning research has a rich history, with many foundational and impactful papers shaping the field. Here are some key research papers and areas to explore:\\n\\n**Seminal and Foundational Papers:**\\n\\n*   **\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950):** While not exclusively about deep learning, this paper laid the groundwork for artificial intelligence and the concept of machine intelligence.\\n*   **\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958):** This paper introduced the perceptron, an early form of artificial neural network, and explored its learning capabilities.\\n*   **\\\"LSTM: Long Short-Term Memory\\\" (1997):** This paper introduced the Long Short-Term Memory (LSTM) architecture, which addressed the vanishing gradient problem in recurrent neural networks (RNNs) and enabled learning long-range dependencies.\\n*   **\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998):** This work by LeCun et al. introduced the LeNet architecture, a pioneering convolutional neural network (CNN) for character recognition.\\n*   **\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012):** Often referred to as the \\\"AlexNet\\\" paper, this work by Krizhevsky, Sutskever, and Hinton demonstrated the power of deep CNNs for image classification, achieving a breakthrough performance on the ImageNet dataset.\\n*   **\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013):** This paper from DeepMind presented the use of deep Q-networks (DQN) to play Atari games, a seminal work in applying deep learning to reinforcement learning.\\n*   **\\\"Generative Adversarial Nets\\\" (2014):** Introduced by Goodfellow et al., GANs provided a novel framework for training generative models by using two competing neural networks.\\n*   **\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014):** This paper proposed the dropout technique, a regularization method that significantly improved the training of deep neural networks.\\n*   **\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014):** This paper introduced the VGG architecture, known for its simplicity and effectiveness in image recognition tasks, demonstrating the benefits of deeper convolutional networks.\\n*   **\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015):** This paper introduced the residual network (ResNet) architecture, which enabled the training of extremely deep neural networks by addressing the degradation problem.\\n*   **\\\"Attention Is All You Need\\\" (2017):** This paper introduced the Transformer architecture, which revolutionized sequence processing, particularly in natural language processing, by relying solely on attention mechanisms.\\n\\n**Key Research Areas and Recent Developments:**\\n\\n*   **Convolutional Neural Networks (CNNs):** Foundational for image recognition and computer vision tasks, with architectures like LeNet, AlexNet, VGG, and ResNet being crucial.\\n*   **Recurrent Neural Networks (RNNs) and LSTMs:** Essential for processing sequential data, such as text and time series.\\n*   **Generative Adversarial Networks (GANs):** Widely used for generating realistic data, including images, and have seen numerous advancements like DCGAN, Wasserstein GAN, and StyleGAN.\\n*   **Transformers:** Have become dominant in Natural Language Processing (NLP) and are increasingly applied in other domains due to their ability to capture long-range dependencies.\\n*   **Deep Reinforcement Learning:** Combines deep learning with reinforcement learning for tasks like game playing (e.g., AlphaGo) and control.\\n*   **Self-supervised Learning and Federated Learning:** Emerging training techniques that aim to reduce reliance on labeled data and enable privacy-preserving model training.\\n*   **Graph Neural Networks (GNNs):** Designed to handle graph-structured data, finding applications in areas like social networks and drug discovery.\\n*   **Nested Learning:** A newer paradigm that treats ML models as interconnected, multi-level optimization problems.\\n*   **Surveys and Reviews:** Comprehensive papers that review the state-of-the-art, applications, and challenges in deep learning are also valuable resources.\\n\\nThis list is not exhaustive, as the field of deep learning is rapidly evolving with new research published continuously. Exploring papers from major conferences like NeurIPS, ICML, ICLR, and CVPR, as well as journals like JMLR, is recommended for staying up-to-date.\"}}}],\"role\":\"user\"}\n{\"parts\":[{\"function_call\":{\"args\":{\"papers\":[\"\\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950)\",\"\\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958)\",\"\\\"LSTM: Long Short-Term Memory\\\" (1997)\",\"\\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998)\",\"\\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012)\",\"\\\"Playing Atari with Deep Reinforcement Learning\\\" (2013)\",\"\\\"Generative Adversarial Nets\\\" (2014)\",\"\\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014)\",\"\\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014)\",\"\\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015)\",\"\\\"Attention Is All You Need\\\" (2017)\"]},\"name\":\"count_papers\"}}],\"role\":\"model\"}\n{\"parts\":[{\"function_response\":{\"name\":\"count_papers\",\"response\":{\"result\":11}}}],\"role\":\"user\"}\n-----------------------------------------------------------\nFunctions:\ngoogle_search_agent: {'request': {'type': <Type.STRING: 'STRING'>}} \ncount_papers: {'papers': {'items': {'type': <Type.STRING: 'STRING'>}, 'type': <Type.ARRAY: 'ARRAY'>}} \n-----------------------------------------------------------\n\nINFO:google_adk.google.adk.models.google_llm:Response received from the model.\nDEBUG:google_adk.google.adk.models.google_llm:\nLLM Response:\n-----------------------------------------------------------\nText:\nHere are some research papers on deep learning:\n\n* \"Computing Machinery and Intelligence\" by Alan Turing (1950)\n* \"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\" by Frank Rosenblatt (1958)\n* \"LSTM: Long Short-Term Memory\" (1997)\n* \"LeNet: Gradient-Based Learning Applied to Document Recognition\" (1998)\n* \"ImageNet Classification with Deep Convolutional Neural Networks\" (2012)\n* \"Playing Atari with Deep Reinforcement Learning\" (2013)\n* \"Generative Adversarial Nets\" (2014)\n* \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\" (2014)\n* \"Very Deep Convolutional Networks for Large-Scale Image Recognition\" (VGG) (2014)\n* \"Deep Residual Learning for Image Recognition\" (ResNet) (2015)\n* \"Attention Is All You Need\" (2017)\n\nThere are a total of 11 research papers.\n-----------------------------------------------------------\nFunction calls:\n\n-----------------------------------------------------------\nRaw response:\n{\"sdk_http_response\":{\"headers\":{\"Content-Type\":\"application/json; charset=UTF-8\",\"Vary\":\"Origin, X-Origin, Referer\",\"Content-Encoding\":\"gzip\",\"Date\":\"Tue, 18 Nov 2025 03:35:05 GMT\",\"Server\":\"scaffolding on HTTPServer2\",\"X-XSS-Protection\":\"0\",\"X-Frame-Options\":\"SAMEORIGIN\",\"X-Content-Type-Options\":\"nosniff\",\"Server-Timing\":\"gfet4t7; dur=992\",\"Transfer-Encoding\":\"chunked\"}},\"candidates\":[{\"content\":{\"parts\":[{\"text\":\"Here are some research papers on deep learning:\\n\\n* \\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950)\\n* \\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958)\\n* \\\"LSTM: Long Short-Term Memory\\\" (1997)\\n* \\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998)\\n* \\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012)\\n* \\\"Playing Atari with Deep Reinforcement Learning\\\" (2013)\\n* \\\"Generative Adversarial Nets\\\" (2014)\\n* \\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014)\\n* \\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014)\\n* \\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015)\\n* \\\"Attention Is All You Need\\\" (2017)\\n\\nThere are a total of 11 research papers.\"}],\"role\":\"model\"},\"finish_reason\":\"STOP\",\"index\":0}],\"model_version\":\"gemini-2.5-flash-lite\",\"response_id\":\"aekbaYiIG4uk1e8Pwq2USA\",\"usage_metadata\":{\"candidates_token_count\":239,\"prompt_token_count\":1482,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":1482}],\"total_token_count\":1721}}\n-----------------------------------------------------------\n\nDEBUG:google_adk.google.adk.cli.adk_web_server:Generated event in agent run streaming: {\"modelVersion\":\"gemini-2.5-flash-lite\",\"content\":{\"parts\":[{\"text\":\"Here are some research papers on deep learning:\\n\\n* \\\"Computing Machinery and Intelligence\\\" by Alan Turing (1950)\\n* \\\"The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain\\\" by Frank Rosenblatt (1958)\\n* \\\"LSTM: Long Short-Term Memory\\\" (1997)\\n* \\\"LeNet: Gradient-Based Learning Applied to Document Recognition\\\" (1998)\\n* \\\"ImageNet Classification with Deep Convolutional Neural Networks\\\" (2012)\\n* \\\"Playing Atari with Deep Reinforcement Learning\\\" (2013)\\n* \\\"Generative Adversarial Nets\\\" (2014)\\n* \\\"Dropout: A Simple Way to Prevent Neural Networks from Overfitting\\\" (2014)\\n* \\\"Very Deep Convolutional Networks for Large-Scale Image Recognition\\\" (VGG) (2014)\\n* \\\"Deep Residual Learning for Image Recognition\\\" (ResNet) (2015)\\n* \\\"Attention Is All You Need\\\" (2017)\\n\\nThere are a total of 11 research papers.\"}],\"role\":\"model\"},\"finishReason\":\"STOP\",\"usageMetadata\":{\"candidatesTokenCount\":239,\"promptTokenCount\":1482,\"promptTokensDetails\":[{\"modality\":\"TEXT\",\"tokenCount\":1482}],\"totalTokenCount\":1721},\"invocationId\":\"e-c38ddd75-ce77-4076-9def-0f33efe9a518\",\"author\":\"research_paper_finder_agent\",\"actions\":{\"stateDelta\":{},\"artifactDelta\":{},\"requestedAuthConfigs\":{},\"requestedToolConfirmations\":{}},\"id\":\"26aad98c-7249-4896-97f5-2b555c57ff2d\",\"timestamp\":1763436904.604999}\n\u001b[32mINFO\u001b[0m:     35.191.82.121:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/6504be05-d05f-4fc2-a791-6aa25c2b9422 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.124:0 - \"\u001b[1mGET /debug/trace/session/6504be05-d05f-4fc2-a791-6aa25c2b9422 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.123:0 - \"\u001b[1mGET /debug/trace/session/6504be05-d05f-4fc2-a791-6aa25c2b9422 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.120:0 - \"\u001b[1mGET /debug/trace/1070a8a3-e186-449a-871d-f6c49e4a7586 HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nDEBUG:google_adk.google.adk.cli.utils.agent_loader:Returning cached agent for research-agent (async)\n\u001b[32mINFO\u001b[0m:     35.191.82.121:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/6504be05-d05f-4fc2-a791-6aa25c2b9422/events/1070a8a3-e186-449a-871d-f6c49e4a7586/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.82.123:0 - \"\u001b[1mGET /debug/trace/ac95934b-eab0-4895-939b-e4bafb44694b HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\nDEBUG:google_adk.google.adk.cli.utils.agent_loader:Returning cached agent for research-agent (async)\n\u001b[32mINFO\u001b[0m:     35.191.82.121:0 - \"\u001b[1mGET /apps/research-agent/users/user/sessions/6504be05-d05f-4fc2-a791-6aa25c2b9422/events/ac95934b-eab0-4895-939b-e4bafb44694b/graph HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m84\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Once the ADK web UI starts, open the proxy link using the button in the previous cell.\n\nAs you start chatting with the agent, you should see the DEBUG logs appear in the output cell below!\n\n‚ÄºÔ∏è **IMPORTANT: DO NOT SHARE THE PROXY LINK** with anyone - treat it as sensitive data as it contains your authentication token in the URL.","metadata":{}},{"cell_type":"markdown","source":"### üìù 2.3: Test the agent in ADK web UI\n\n#### **üëâ Do: In the ADK web UI**\n\n1. Select \"research-agent\" from the dropdown in the top-left.\n2. In the chat interface, type: `Find latest quantum computing papers`\n3. Send the message and observe the response. The agent should return a list of research papers and their count.\n\nIt looks like our agent works and we got a response! ü§î **But wait, isn't the count of papers unusually large? Let's look at the logs and trace.** ","metadata":{}},{"cell_type":"markdown","source":"#### **üëâ Do: Events tab - Traces in detail**\n\n1. In the web UI, click the **\"Events\"** tab on the left sidebar\n2. You'll see a chronological list of all agent actions\n3. Click on any event to expand its details in the bottom panel\n4. Try clicking the **\"Trace\"** button to see timing information for each step.\n5. **Click the `execute_tool count_papers` span. You'll see that the function call to `count_papers` returns the large number as the response**.\n6. Let's look at what was passed as input to this function. \n7. **Find the `call_llm` span corresponding to the `count_papers` function call**.","metadata":{}},{"cell_type":"markdown","source":"#### **üëâ Do: Inspect the Function call in Events:**\n\n- Click on the specific span to open the Events tab.\n- Examine the `function_call`, focusing on the `papers` argument.\n- Notice that `root_agent` passes the list of `papers` as a **str** instead of a **List[str]** - there's our bug! ","metadata":{}},{"cell_type":"markdown","source":"![Demo](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/observability-demo.gif)","metadata":{}},{"cell_type":"markdown","source":"### 2.4: Your Turn - fix it! üëæ \n\nUpdate the datatype of the `papers` argument in the `count_papers` tool to a `List[str]` and rerun the `adk web` command!","metadata":{}},{"cell_type":"markdown","source":"---\n\n## ‚ÄºÔ∏è **Stop the ADK web UI** üõë\n\n**In order to run cells in the remainder of this notebook,** please stop the running cell where you started `adk web` in Section 3.1.\n\nOtherwise that running cell will block / prevent other cells from running as long as the ADK web UI is running.\n\n---","metadata":{}},{"cell_type":"markdown","source":"### 2.5: Debug through local Logs\n\nOptionally, you can also examine the local DEBUG logs to find the root cause. Run the following cell to print the contents of the log file. Look for detailed logs like:\n```\nDEBUG - google_adk.models.google_llm - LLM Request: ...\nDEBUG - google_adk.models.google_llm - LLM Response: ...\n```","metadata":{}},{"cell_type":"code","source":"# Check the DEBUG logs from the broken agent\nprint(\"üîç Examining web server logs for debugging clues...\\n\")\n!cat logger.log","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:36:37.872863Z","iopub.execute_input":"2025-11-18T03:36:37.873301Z","iopub.status.idle":"2025-11-18T03:36:37.999158Z","shell.execute_reply.started":"2025-11-18T03:36:37.873264Z","shell.execute_reply":"2025-11-18T03:36:37.997866Z"}},"outputs":[{"name":"stdout","text":"üîç Examining web server logs for debugging clues...\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**Other Observability questions you can now answer from logs and adk web:**\n- **Efficiency**: Is the agent making optimal tool choices?\n- **Reasoning Quality**: Are the prompts well-structured and context-appropriate?\n- **Performance**: Look at the traces to identify which steps take the longest?\n- **Failure Diagnosis**: When something goes wrong, where exactly did it fail?\n\n**Key Learning:** Core debugging pattern: `symptom ‚Üí logs ‚Üí root cause ‚Üí fix`.\n\n**Debugging Victory:** You just went from \"Agent mysteriously failed\" to \"I know exactly why and how to fix it!\" This is the power of observability!\n","metadata":{}},{"cell_type":"markdown","source":"---\n## üßë‚Äçüíª Section 3: Logging in production\n\n**üéØ Great! You can now debug agent failures using ADK web UI and DEBUG logs.**\n\nBut what happens when you move beyond development? Real-world scenarios where you need to move beyond the web UI:\n\n**‚ùå Problem 1: Production Deployment**\n```\nYou: \"Let me open the ADK web UI to check why the agent failed\"\nDevOps: \"Um... this is a production server. No web UI access.\"\nYou: üò± \"How do I debug production issues?\"\n```\n\n**‚ùå Problem 2: Automated Systems** \n```\nYou: \"The agent runs 1000 times per day in our pipeline\"\nBoss: \"Which runs are slow? What's our success rate?\"\nYou: üò∞ \"I'd have to manually check the web UI 1000 times...\"\n```\n\n**üí° The Solution:**\n\nWe need a way to capture observability data or in other words, **add logs to our code**. \n\nüëâ In traditional software development, this is done by adding log statements in Python functions - **and agents are no different!** We need to add log statements to our agent and a common approach is to add log statements to **Plugins**.\n","metadata":{}},{"cell_type":"markdown","source":"### 3.1: How to add logs for production observability?\n\nA Plugin is a custom code module that runs automatically at various stages of your agent's lifecycle. Plugins are composed of \"**Callbacks**\" which provide the hooks to interrupt an agent's flow. Think of it like this:\n\n- **Your agent workflow**: User message ‚Üí Agent thinks ‚Üí Calls tools ‚Üí Returns response\n- **Plugin hooks into this**: Before agent starts ‚Üí After tool runs ‚Üí When LLM responds ‚Üí etc.\n- **Plugin contains your custom code**: Logging, monitoring, security checks, caching, etc.","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/plugins-callbacks.png)","metadata":{}},{"cell_type":"markdown","source":"#### Callbacks\n\nCallbacks are the **atomic components inside a Plugin** - these are just Python functions that run at specific points in an agent's lifecycle! **Callbacks are grouped together to create a Plugin.**\n\nThere are different kinds of callbacks such as:\n* **before/after_agent_callbacks** - runs before/after an agent is invoked\n* **before/after_tool_callbacks** - runs before/after a tool is called\n* **before/after_model_callbacks** - similarly, runs before/after the LLM model is called\n* **on_model_error_callback** - which runs when a model error is encountered","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/types_of_callbacks.png)","metadata":{}},{"cell_type":"markdown","source":"### 3.2: To make things more concrete, what does a Plugin look like?","metadata":{}},{"cell_type":"code","source":"print(\"----- EXAMPLE PLUGIN - DOES NOTHING ----- \")\n\nimport logging\nfrom google.adk.agents.base_agent import BaseAgent\nfrom google.adk.agents.callback_context import CallbackContext\nfrom google.adk.models.llm_request import LlmRequest\nfrom google.adk.plugins.base_plugin import BasePlugin\n\n\n# Applies to all agent and model calls\nclass CountInvocationPlugin(BasePlugin):\n    \"\"\"A custom plugin that counts agent and tool invocations.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the plugin with counters.\"\"\"\n        super().__init__(name=\"count_invocation\")\n        self.agent_count: int = 0\n        self.tool_count: int = 0\n        self.llm_request_count: int = 0\n\n    # Callback 1: Runs before an agent is called. You can add any custom logic here.\n    async def before_agent_callback(\n        self, *, agent: BaseAgent, callback_context: CallbackContext\n    ) -> None:\n        \"\"\"Count agent runs.\"\"\"\n        self.agent_count += 1\n        logging.info(f\"[Plugin] Agent run count: {self.agent_count}\")\n\n    # Callback 2: Runs before a model is called. You can add any custom logic here.\n    async def before_model_callback(\n        self, *, callback_context: CallbackContext, llm_request: LlmRequest\n    ) -> None:\n        \"\"\"Count LLM requests.\"\"\"\n        self.llm_request_count += 1\n        logging.info(f\"[Plugin] LLM request count: {self.llm_request_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:40:24.013788Z","iopub.execute_input":"2025-11-18T03:40:24.014239Z","iopub.status.idle":"2025-11-18T03:40:55.153374Z","shell.execute_reply.started":"2025-11-18T03:40:24.014201Z","shell.execute_reply":"2025-11-18T03:40:55.151311Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"----- EXAMPLE PLUGIN - DOES NOTHING ----- \n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/548061578.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallbackContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_request\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlmRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrunners\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minvocation_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInvocationContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlive_request_queue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiveRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTypeAlias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_actions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventActions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtelemetry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/events/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevent_actions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventActions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/events/event.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_response\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlmResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevent_actions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventActions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapigee_llm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApigeeLlm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_llm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseLlm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgemma_llm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgoogle_llm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllm_request\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlmRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/gemma_llm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle_llm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGemini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_request\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlmRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_response\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLlmResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariant_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleLLMVariant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/llm_request.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_cache_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContextCacheConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_tool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcache_metadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCacheMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/tools/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth_tool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAuthToolArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magent_tool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapihub_tool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapihub_toolset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAPIHubToolset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_tool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseTool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/tools/agent_tool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_automatic_function_calling_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon_configs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgentRefConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_memory_memory_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryMemoryService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAclosing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_forwarding_artifact_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mForwardingArtifactService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/memory/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvertex_ai_rag_memory_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVertexAiRagMemoryService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VertexAiRagMemoryService'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/memory/vertex_ai_rag_memory_service.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertexai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_memory_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMemoryService\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase_memory_service\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchMemoryResponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/dependencies/vertexai.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreview\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexample_stores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreview\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/preview/example_stores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# pylint: disable=g-multiple-import,g-importing-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1beta1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m from vertexai.example_stores._example_stores import (\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mContentsExample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mContentSearchKey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/example_stores/_example_stores.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1beta1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerative_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_engines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0m_LOGGER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/agent_engines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# We just want to re-export certain classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: disable=g-multiple-import,g-importing-member\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m from vertexai.agent_engines._agent_engines import (\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0m_AgentEngineInterface\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mAgentEngine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/agent_engines/_agent_engines.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maip_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maiplatform_v1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreasoning_engine_service\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_engines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/agent_engines/_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     _PACKAGE_DISTRIBUTIONS: Mapping[str, Sequence[str]] = (\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mimportlib_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     return {\n\u001b[1;32m   1086\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     }\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    605\u001b[0m             make_files(\n\u001b[1;32m    606\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/importlib_metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         return skip_missing_files(\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m         \"\"\"\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \"\"\"\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"markdown","source":"**Key insight**: You register a plugin **once** on your runner, and it automatically applies to **every agent, tool call, and LLM request** in your system as per your definition. Read more about Plugin hooks [here](https://google.github.io/adk-docs/plugins/#plugin-callback-hooks).","metadata":{}},{"cell_type":"markdown","source":"You can follow along with the numbers in the diagram below to understand the flow.","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/count-invocation-plugin.png)","metadata":{}},{"cell_type":"markdown","source":"### 3.3: ADK's built-in `LoggingPlugin`\n\nBut you don't have to define all the callbacks and plugins to capture *standard* Observability data in ADK. Instead, ADK provides a built-in **LoggingPlugin** that automatically captures all agent activity:\n\n- üöÄ User messages and agent responses\n- ‚è±Ô∏è Timing data for performance analysis\n- üß† LLM requests and responses for debugging\n- üîß Tool calls and results\n- ‚úÖ Complete execution traces","metadata":{}},{"cell_type":"markdown","source":"#### Agent definition\n\nLet's use the same agent from the previous demo - the Research paper finder!","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.tools.agent_tool import AgentTool\nfrom google.adk.tools.google_search_tool import google_search\n\nfrom google.genai import types\nfrom typing import List\n\nretry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)\n\n\ndef count_papers(papers: List[str]):\n    \"\"\"\n    This function counts the number of papers in a list of strings.\n    Args:\n      papers: A list of strings, where each string is a research paper.\n    Returns:\n      The number of papers in the list.\n    \"\"\"\n    return len(papers)\n\n\n# Google search agent\ngoogle_search_agent = LlmAgent(\n    name=\"google_search_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    description=\"Searches for information using Google search\",\n    instruction=\"Use the google_search tool to find information on the given topic. Return the raw search results.\",\n    tools=[google_search],\n)\n\n# Root agent\nresearch_agent_with_plugin = LlmAgent(\n    name=\"research_paper_finder_agent\",\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    instruction=\"\"\"Your task is to find research papers and count them. \n   \n   You must follow these steps:\n   1) Find research papers on the user provided topic using the 'google_search_agent'. \n   2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.\n   3) Return both the list of research papers and the total number of papers.\n   \"\"\",\n    tools=[AgentTool(agent=google_search_agent), count_papers],\n)\n\nprint(\"‚úÖ Agent created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:43:47.437693Z","iopub.execute_input":"2025-11-18T03:43:47.438094Z","iopub.status.idle":"2025-11-18T03:43:51.534508Z","shell.execute_reply.started":"2025-11-18T03:43:47.438070Z","shell.execute_reply":"2025-11-18T03:43:51.533214Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Agent created\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"### 3.4: Add LoggingPlugin to Runner\n\nThe following code creates the `InMemoryRunner`. This is used to programmatically invoke the agent.\n\n**To use `LoggingPlugin` in the above research agent,**\n1) Import the plugin\n2) Add it when initializing the `InMemoryRunner`.\n","metadata":{}},{"cell_type":"code","source":"from google.adk.runners import InMemoryRunner\nfrom google.adk.plugins.logging_plugin import (\n    LoggingPlugin,\n)  # <---- 1. Import the Plugin\nfrom google.genai import types\nimport asyncio\n\nrunner = InMemoryRunner(\n    agent=research_agent_with_plugin,\n    plugins=[\n        LoggingPlugin()\n    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents\n)\n\nprint(\"‚úÖ Runner configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:44:31.542693Z","iopub.execute_input":"2025-11-18T03:44:31.543112Z","iopub.status.idle":"2025-11-18T03:44:31.551851Z","shell.execute_reply.started":"2025-11-18T03:44:31.543084Z","shell.execute_reply":"2025-11-18T03:44:31.550541Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Runner configured\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Let's now run the agent using `run_debug` function.","metadata":{}},{"cell_type":"code","source":"print(\"üöÄ Running agent with LoggingPlugin...\")\nprint(\"üìä Watch the comprehensive logging output below:\\n\")\n\nresponse = await runner.run_debug(\"Find recent papers on quantum computing\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T03:44:38.037729Z","iopub.execute_input":"2025-11-18T03:44:38.038098Z","iopub.status.idle":"2025-11-18T03:44:46.413355Z","shell.execute_reply.started":"2025-11-18T03:44:38.038073Z","shell.execute_reply":"2025-11-18T03:44:46.411862Z"}},"outputs":[{"name":"stdout","text":"üöÄ Running agent with LoggingPlugin...\nüìä Watch the comprehensive logging output below:\n\n\n ### Created new session: debug_session_id\n\nUser > Find recent papers on quantum computing\n\u001b[90m[logging_plugin] üöÄ USER MESSAGE RECEIVED\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-fc83db5c-839f-47e9-9f7d-9bba1369f90c\u001b[0m\n\u001b[90m[logging_plugin]    Session ID: debug_session_id\u001b[0m\n\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n\u001b[90m[logging_plugin]    Root Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    User Content: text: 'Find recent papers on quantum computing'\u001b[0m\n\u001b[90m[logging_plugin] üèÉ INVOCATION STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-fc83db5c-839f-47e9-9f7d-9bba1369f90c\u001b[0m\n\u001b[90m[logging_plugin]    Starting Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin] ü§ñ AGENT STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Agent Name: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-fc83db5c-839f-47e9-9f7d-9bba1369f90c\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM REQUEST\u001b[0m\n\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    System Instruction: 'Your task is to find research papers and count them. \n   \n   You must follow these steps:\n   1) Find research papers on the user provided topic using the 'google_search_agent'. \n   2) Then, pass the p...'\u001b[0m\n\u001b[90m[logging_plugin]    Available Tools: ['google_search_agent', 'count_papers']\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM RESPONSE\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_call: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Token Usage - Input: 242, Output: 21\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: 39161c58-51af-4227-8157-9a45de0ab78f\u001b[0m\n\u001b[90m[logging_plugin]    Author: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_call: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n\u001b[90m[logging_plugin]    Function Calls: ['google_search_agent']\u001b[0m\n\u001b[90m[logging_plugin] üîß TOOL STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Tool Name: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Function Call ID: adk-57d86111-5249-45c4-851d-6bea18d37347\u001b[0m\n\u001b[90m[logging_plugin]    Arguments: {'request': 'recent papers on quantum computing'}\u001b[0m\n\u001b[90m[logging_plugin] üöÄ USER MESSAGE RECEIVED\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-e1cd3797-a734-4310-b9c2-a57594557a0b\u001b[0m\n\u001b[90m[logging_plugin]    Session ID: f1e087fe-0e37-44bf-b815-412cd3bcf7d1\u001b[0m\n\u001b[90m[logging_plugin]    User ID: debug_user_id\u001b[0m\n\u001b[90m[logging_plugin]    App Name: InMemoryRunner\u001b[0m\n\u001b[90m[logging_plugin]    Root Agent: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    User Content: text: 'recent papers on quantum computing'\u001b[0m\n\u001b[90m[logging_plugin] üèÉ INVOCATION STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-e1cd3797-a734-4310-b9c2-a57594557a0b\u001b[0m\n\u001b[90m[logging_plugin]    Starting Agent: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin] ü§ñ AGENT STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Agent Name: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-e1cd3797-a734-4310-b9c2-a57594557a0b\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM REQUEST\u001b[0m\n\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n\u001b[90m[logging_plugin]    Agent: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    System Instruction: 'Use the google_search tool to find information on the given topic. Return the raw search results.\n\nYou are an agent. Your internal name is \"google_search_agent\". The description about you is \"Searches...'\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM RESPONSE\u001b[0m\n\u001b[90m[logging_plugin]    Agent: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: text: 'Recent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubit stability, and the development of more powerful quantum proces...'\u001b[0m\n\u001b[90m[logging_plugin]    Token Usage - Input: 58, Output: 546\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: d4dd64f5-4f17-4ff3-b8e4-d8d2b94d3342\u001b[0m\n\u001b[90m[logging_plugin]    Author: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: text: 'Recent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubit stability, and the development of more powerful quantum proces...'\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\n\u001b[90m[logging_plugin] ü§ñ AGENT COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Agent Name: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-e1cd3797-a734-4310-b9c2-a57594557a0b\u001b[0m\n\u001b[90m[logging_plugin] ‚úÖ INVOCATION COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-e1cd3797-a734-4310-b9c2-a57594557a0b\u001b[0m\n\u001b[90m[logging_plugin]    Final Agent: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin] üîß TOOL COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Tool Name: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Function Call ID: adk-57d86111-5249-45c4-851d-6bea18d37347\u001b[0m\n\u001b[90m[logging_plugin]    Result: Recent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubit stability, and the development of more powerful quantum processors. Companies like Google, IBM, Microsoft, and research institutions such as Harvard and Princeton...}\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: 63a9995b-e25b-4492-b9b7-864ae3b3a42b\u001b[0m\n\u001b[90m[logging_plugin]    Author: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_response: google_search_agent\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n\u001b[90m[logging_plugin]    Function Responses: ['google_search_agent']\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM REQUEST\u001b[0m\n\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    System Instruction: 'Your task is to find research papers and count them. \n   \n   You must follow these steps:\n   1) Find research papers on the user provided topic using the 'google_search_agent'. \n   2) Then, pass the p...'\u001b[0m\n\u001b[90m[logging_plugin]    Available Tools: ['google_search_agent', 'count_papers']\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM RESPONSE\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_call: count_papers\u001b[0m\n\u001b[90m[logging_plugin]    Token Usage - Input: 797, Output: 532\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: fc3273e7-796f-4057-bc3a-ec4bb08caf5e\u001b[0m\n\u001b[90m[logging_plugin]    Author: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_call: count_papers\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n\u001b[90m[logging_plugin]    Function Calls: ['count_papers']\u001b[0m\n\u001b[90m[logging_plugin] üîß TOOL STARTING\u001b[0m\n\u001b[90m[logging_plugin]    Tool Name: count_papers\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Function Call ID: adk-1bbd3caf-970d-4645-8e68-e14cc1c7a221\u001b[0m\n\u001b[90m[logging_plugin]    Arguments: {'papers': ['Recent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubit stability, and the development of more powerful quantum processors. Companies like Google, IBM, Microsoft, and research institutions such as Harvard ...}\u001b[0m\n\u001b[90m[logging_plugin] üîß TOOL COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Tool Name: count_papers\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Function Call ID: adk-1bbd3caf-970d-4645-8e68-e14cc1c7a221\u001b[0m\n\u001b[90m[logging_plugin]    Result: 1\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: b4210cb2-dd3e-4887-b171-03bfc30e866c\u001b[0m\n\u001b[90m[logging_plugin]    Author: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: function_response: count_papers\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: False\u001b[0m\n\u001b[90m[logging_plugin]    Function Responses: ['count_papers']\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM REQUEST\u001b[0m\n\u001b[90m[logging_plugin]    Model: gemini-2.5-flash-lite\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    System Instruction: 'Your task is to find research papers and count them. \n   \n   You must follow these steps:\n   1) Find research papers on the user provided topic using the 'google_search_agent'. \n   2) Then, pass the p...'\u001b[0m\n\u001b[90m[logging_plugin]    Available Tools: ['google_search_agent', 'count_papers']\u001b[0m\n\u001b[90m[logging_plugin] üß† LLM RESPONSE\u001b[0m\n\u001b[90m[logging_plugin]    Agent: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: text: 'The following research papers were found on quantum computing:\n\nRecent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubi...'\u001b[0m\n\u001b[90m[logging_plugin]    Token Usage - Input: 1344, Output: 534\u001b[0m\n\u001b[90m[logging_plugin] üì¢ EVENT YIELDED\u001b[0m\n\u001b[90m[logging_plugin]    Event ID: 3511eded-ca0e-4648-9674-955aa007dc8e\u001b[0m\n\u001b[90m[logging_plugin]    Author: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Content: text: 'The following research papers were found on quantum computing:\n\nRecent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubi...'\u001b[0m\n\u001b[90m[logging_plugin]    Final Response: True\u001b[0m\nresearch_paper_finder_agent > The following research papers were found on quantum computing:\n\nRecent research in quantum computing, particularly in 2024 and early 2025, highlights significant advancements in error correction, qubit stability, and the development of more powerful quantum processors. Companies like Google, IBM, Microsoft, and research institutions such as Harvard and Princeton are at the forefront of these developments.\n\nKey areas of progress include:\n\n*   **Quantum Error Correction:** Researchers are making substantial strides in developing techniques to detect and correct errors in qubits, which is crucial for building reliable and scalable quantum computers. Harvard researchers, for instance, have demonstrated a new system capable of detecting and removing errors below a key performance threshold, creating a foundation for practical large-scale quantum computation.\n*   **Qubit Technology and Stability:** New qubit designs are emerging that offer improved coherence times and stability. For example, Princeton engineers have created a tantalum-silicon qubit that remains stable for over a millisecond, significantly longer than existing devices and compatible with current quantum chip architectures. Google's Willow chip, unveiled in December 2024, is a 105-qubit superconducting processor that surpasses previous models in coherence times and computational capabilities.\n*   **Logical Qubits:** The focus is shifting from physical qubits to \"logical qubits,\" which are protected from errors and have higher fidelity. Many companies are now working to implement these theories in practice, aiming to build quantum processors based on logical qubits. Microsoft and Quantinuum have demonstrated entangling 12 logical qubits, a tripling of their previous count.\n*   **Quantum Processors and Scaling:** Quantum chips with over 100 qubits are already available and being used for research. IBM is working towards a quantum-centric supercomputer for launch in 2025, and their \"Kookaburra\" system is expected to have 4,158 qubits formed by linking three chips. Advances are also being made in interconnecting multiple quantum computers to create larger virtual systems.\n*   **Algorithms and Software:** Alongside hardware advancements, there's significant research and development in quantum software and algorithms. Google Quantum AI has introduced a new quantum algorithm called Decoded Quantum Interferometry (DQI), which could enable large-scale quantum computers to solve certain optimization problems that are intractable for classical computers.\n\nThe year 2025 has been designated the International Year of Quantum Science and Technology, underscoring the global interest and investment in this rapidly advancing field. The potential applications span medicine, chemistry, materials science, and cybersecurity.\n\nThere is a total of 1 paper.\n\u001b[90m[logging_plugin] ü§ñ AGENT COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Agent Name: research_paper_finder_agent\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-fc83db5c-839f-47e9-9f7d-9bba1369f90c\u001b[0m\n\u001b[90m[logging_plugin] ‚úÖ INVOCATION COMPLETED\u001b[0m\n\u001b[90m[logging_plugin]    Invocation ID: e-fc83db5c-839f-47e9-9f7d-9bba1369f90c\u001b[0m\n\u001b[90m[logging_plugin]    Final Agent: research_paper_finder_agent\u001b[0m\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"---\n\n## üìä Summary\n\n**‚ùì When to use which type of Logging?**\n1. **Development debugging?** ‚Üí Use `adk web --log_level DEBUG`\n2. **Common production observability?** ‚Üí Use `LoggingPlugin()` \n3. **Custom requirements?** ‚Üí Build Custom Callbacks and Plugins\n\n### Try it out!\n\nüëâ Extend the agent's observability by implementing a **custom ADK plugin** that tracks and reports the total number of tool calls made during a session.","metadata":{}},{"cell_type":"markdown","source":"## üéØ Congratulations!\n\n**You now know how to:**\n\n- ‚úÖ Debug agent failures through DEBUG logs and the ADK web UI\n- ‚úÖ Use the core debugging pattern: symptom ‚Üí logs ‚Üí root cause ‚Üí fix  \n- ‚úÖ Scale observability with `LoggingPlugin` for production systems\n- ‚úÖ Understand when to use the different logging types\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"markdown","source":"### üìö Resources\n\n**Refer to the ADK documentation to learn more about observability:**\n\n- [ADK Observability Documentation](https://google.github.io/adk-docs/observability/logging/) - Complete guide to logging in ADK\n- [Custom Plugin](https://google.github.io/adk-docs/plugins/) - Build your own Plugins\n- [External Integrations](https://google.github.io/adk-docs/observability/cloud-trace/) - Explore external third-party observability integrations with ADK\n\n### üéØ Next Steps\n\nReady for the next challenge? Continue to the next notebook to learn how to **Evaluate an Agent** and ensure it's working as expected in production.","metadata":{"execution":{"iopub.execute_input":"2025-10-24T01:50:15.542601Z","iopub.status.busy":"2025-10-24T01:50:15.542221Z","iopub.status.idle":"2025-10-24T01:50:15.548614Z","shell.execute_reply":"2025-10-24T01:50:15.547556Z","shell.execute_reply.started":"2025-10-24T01:50:15.542577Z"}}},{"cell_type":"markdown","source":"---\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <th style=\"text-align:center\">Authors</th>\n    </tr>\n    <tr>\n      <td style=\"text-align:center\"><a href=\"https://www.linkedin.com/in/sitalakshmi04/\">Sita Lakshmi Sangameswaran</a></td>\n    </tr>\n  </table>\n</div>","metadata":{}}]}