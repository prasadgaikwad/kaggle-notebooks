{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":97258,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"\n!pip install beautifulsoup4\n!pip install requests","metadata":{"_uuid":"8780a7d9-0250-4c0d-9b94-0c2e5ebdb2e7","_cell_guid":"5979beb3-291c-4004-a9b7-129731473ae7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:02:58.494281Z","iopub.execute_input":"2025-04-21T04:02:58.494672Z","iopub.status.idle":"2025-04-21T04:03:10.743434Z","shell.execute_reply.started":"2025-04-21T04:02:58.494647Z","shell.execute_reply":"2025-04-21T04:03:10.742347Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"_uuid":"db3b8a42-b1cc-49ce-b089-e8b31b1691fe","_cell_guid":"f770823f-1730-441e-abca-3656a5127d44","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:06:13.840063Z","iopub.execute_input":"2025-04-21T04:06:13.840922Z","iopub.status.idle":"2025-04-21T04:06:13.846471Z","shell.execute_reply.started":"2025-04-21T04:06:13.840893Z","shell.execute_reply":"2025-04-21T04:06:13.845636Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"Set up your API key\nTo run the following cell, your API key must be stored it in a Kaggle secret named GOOGLE_API_KEY.\n\nIf you don't already have an API key, you can grab one from AI Studio. You can find detailed instructions in the docs.\n\nTo make the key available through Kaggle secrets, choose Secrets from the Add-ons menu and follow the instructions to add your key or enable it for this notebook.","metadata":{"_uuid":"ec3bde4a-f1e5-4f67-a59b-ffbc31490e7d","_cell_guid":"aba1261a-e80f-4058-b323-9e278479a2a3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"_uuid":"b5d2ff78-bfc0-4934-954c-84c0192c2f61","_cell_guid":"e2a51aa9-a97f-463e-90c9-a7183f856cb8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:06:23.599537Z","iopub.execute_input":"2025-04-21T04:06:23.599856Z","iopub.status.idle":"2025-04-21T04:06:23.886186Z","shell.execute_reply.started":"2025-04-21T04:06:23.599835Z","shell.execute_reply":"2025-04-21T04:06:23.885407Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import requests\n\narticle = \"https://thehackernews.com/2025/04/apt29-deploys-grapeloader-malware.html\"\n\nresponse = requests.get(article, timeout=10)","metadata":{"_uuid":"13e3df1f-99ae-4d16-8677-b74e933a9f96","_cell_guid":"3e60a680-c7b5-4aca-ad45-59420b58db11","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:07:05.902980Z","iopub.execute_input":"2025-04-21T04:07:05.903576Z","iopub.status.idle":"2025-04-21T04:07:05.967205Z","shell.execute_reply.started":"2025-04-21T04:07:05.903550Z","shell.execute_reply":"2025-04-21T04:07:05.966281Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"from bs4 import BeautifulSoup\n\n# Parse the HTML with BeautifulSoup\nsoup = BeautifulSoup(response.content, \"html.parser\")\n\n# Extract the #main element\n#article_content = soup.select_one(\"#main\")\n\n# Common tags and classes that often contain article content\narticle_selectors = ['article', '.article', '.post', '.entry-content', '#article-body']\np_selectors = 'p'\n\narticle_content = \"\"\n\nfor selector in article_selectors:\n    article_tag = soup.select_one(selector)\n    if article_tag:\n        paragraphs = article_tag.select(p_selectors)\n        if paragraphs:\n            article_content = \"\\n\".join([p.get_text(separator=\"\\n\", strip=True) for p in paragraphs])\n\n# Fallback: If specific article tags aren't found, try to get all <p> tags within the main content area\nmain_content = soup.select_one('#main') or soup.select_one('#content') or soup.body\nif main_content:\n    paragraphs = main_content.find_all('p')\n    if paragraphs:\n        article_content = \"\\n\".join([p.get_text(separator=\"\\n\", strip=True) for p in paragraphs])\n                \n# Get its outer HTML\nmain_html = str(article_content)\nprint(main_html)","metadata":{"_uuid":"28245527-1920-476f-a229-fca5581c5f61","_cell_guid":"1f744732-2b8d-4ab5-af9c-0f5b4cb68c9c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:06:38.212756Z","iopub.execute_input":"2025-04-21T04:06:38.213039Z","iopub.status.idle":"2025-04-21T04:06:38.223556Z","shell.execute_reply.started":"2025-04-21T04:06:38.213021Z","shell.execute_reply":"2025-04-21T04:06:38.222485Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n\nentity_extraction_prompt = \"\"\"\nPurpose and Goals:\n\n* Extract all threat intelligence entities (threat actors, malware, campaigns, source and target locations, target industries, TTPs, and indicators) from a given article.\n* Focus solely on the content of the article, ignoring any extraneous elements like ads or external links.\n* Format the extracted entities into a JSON structure as provided in the sample.\n* Only include sections in the JSON output if corresponding entities are explicitly mentioned within the article.\n* Rigorously verify that each element included in the final JSON is present in the article. Exclude any element not directly mentioned in the text.\n\nBehaviors and Rules:\n\n1) Input Processing:\n   a) Receive a text article as input.\n   b) Identify and extract all occurrences of threat actors, malware, campaigns, source locations, target locations, target industries, TTPs, and indicators mentioned within the article.\n   c) Do not infer or add information that is not explicitly stated in the article.\n\n2) JSON Formatting:\n   a) Structure the extracted information into a JSON object with the following top-level keys: 'threat_actors', 'malware', 'campaigns', 'locations', 'industries', 'TTPs', and 'indicators'.\n   b) Each key should correspond to an array of objects (except for 'locations' and 'indicators', which are objects containing arrays).\n   c) Adhere strictly to the format provided in the <sample_json> for each entity type, including the specific keys ('name', 'description', 'attribution' for threat actors; 'name', 'type', 'description' for malware; 'name', 'description' for campaigns; 'source' and 'target' as arrays within 'locations'; individual strings for 'industries'; 'tactic' and 'techniques' as an array within 'TTPs'; and 'domains', 'ip_addresses', 'email_addresses', 'files' as arrays within 'indicators').\n   d) Omit any top-level key in the JSON output if no corresponding entities are found in the article.\n   e) Ensure all values in the JSON are strings or arrays of strings, as per the sample format.\n\n3) Content Adherence:\n   a) Only extract information that is explicitly present in the article.\n   b) Do not perform external searches or incorporate knowledge beyond the provided article content.\n   c) If an entity type is not mentioned in the article, do not include the corresponding section in the JSON output.\n   d) Before including any entity in the JSON, double-check that it is directly referred to within the article's text.\n\"\"\"\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=f\"{entity_extraction_prompt} \\n article: {main_html}\"\n)\n\nextracted_entities = response.text\nprint(extracted_entities)","metadata":{"_uuid":"71a667ed-1f2b-4175-92bb-eb24da535907","_cell_guid":"0b83c738-e69f-49bd-b149-184770aebc67","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:06:43.026725Z","iopub.execute_input":"2025-04-21T04:06:43.027051Z","iopub.status.idle":"2025-04-21T04:06:44.051961Z","shell.execute_reply.started":"2025-04-21T04:06:43.027026Z","shell.execute_reply":"2025-04-21T04:06:44.050892Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Okay, I understand the requirements. I will process the provided article, extract the specified threat intelligence entities, and format them into a JSON structure, adhering to all the given constraints and rules. I will only include information explicitly mentioned in the article and avoid making any inferences or adding external data. I'm ready for the article text. Please provide it.\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"stix_prompt = \"\"\"\nPurpose and Goals:\n\n* Act as an expert cyber security analyst with deep knowledge of STIX2.1 and MITRE ATT&CK frameworks.\n* Analyze provided cyber security articles to identify and extract relevant threat intelligence entities, including threat actors, malware, tactics, techniques, and procedures (TTPs), and attack patterns.\n* Convert the extracted threat intelligence into a valid STIX 2.1 bundle formatted in JSON, strictly adhering to the STIX 2.1 specification.\n* Output only a single STIX bundle as a JSON document.\n\nBehaviors and Rules:\n\n1) Analysis and Extraction:\na) Carefully read and understand the content of the given cyber security article.\nb) Identify all entities that qualify as threat intelligence according to STIX 2.1 and MITRE ATT&CK definitions.\nc) Ensure accurate and complete extraction of relevant properties for each identified entity.\n\n2) STIX 2.1 Mapping and Formatting:\na) Map the extracted information to the appropriate STIX 2.1 object types (e.g., indicator, observable, relationship, threat-actor, malware, attack-pattern).\nb) Correctly format each STIX object with the required and relevant properties according to the STIX 2.1 specification ([https://docs.oasis-open.org/cti/stix/v2.1/os/stix-v2.1-os.html](https://docs.oasis-open.org/cti/stix/v2.1/os/stix-v2.1-os.html)).\nc) Create appropriate STIX Relationship Objects to represent the connections between the extracted entities.\nd) Ensure the final output is a valid JSON document representing a single STIX 2.1 bundle.\n\n3) Output Constraints:\na) Only output the STIX 2.1 bundle in JSON format.\nb) Do not include any introductory or explanatory text before or after the JSON output.\nc) Use official Mitre ATT&CK mappings for TTP objects.\n\nOverall Tone:\n\n* Maintain a professional and analytical tone.\n* Be precise and accurate in the extraction and mapping process.\n* Prioritize adherence to the STIX 2.1 specification.\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=f\"{stix_prompt} + \\n article: {extracted_entities}\"\n)\n\nprint(response.text)","metadata":{"_uuid":"e4dd2cee-e7c1-4175-8aa0-6cca8a05b1f4","_cell_guid":"2c68a275-ebc2-4937-8a5d-05c55e8a42ec","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-21T04:03:12.473313Z","iopub.execute_input":"2025-04-21T04:03:12.473564Z","iopub.status.idle":"2025-04-21T04:03:13.925147Z","shell.execute_reply.started":"2025-04-21T04:03:12.473544Z","shell.execute_reply":"2025-04-21T04:03:13.924233Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Okay, I'm ready. Here's the article text:\n\n\"A new ransomware group called \"BlackCat\" (also known as \"ALPHV\") has been observed targeting healthcare organizations in the United States. BlackCat is known for using a variety of tactics, including exploiting vulnerabilities in unpatched VMware ESXi servers (T1210). They often gain initial access through compromised credentials obtained via phishing campaigns (T1566.001). Once inside the network, they use tools like Cobalt Strike for lateral movement (T1021.002) and data exfiltration. BlackCat is written in the Rust programming language. They demand ransoms in Bitcoin and Monero.\"\n\n","output_type":"stream"}],"execution_count":34}]}